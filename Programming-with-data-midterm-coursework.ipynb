{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premier League Football : analysis on overall team performance over 27 seasons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Introduction/contex-\n",
    "Over the past decade, the way of analyzing a performance of sports players or teams has shifted to more on numbers. \n",
    "It became more com\n",
    "nu,bers numbers numbers ....etc etc etc \n",
    "\n",
    "Analysis on this project will focus on performance of each team rather than performance of individual players. The analysis will be from simple stats to some complex stats. For instance, number of goals, wins and average number of free kicks per match. The details of what is being a target of analysis are within this notebook. Basic stats are still capable to show the performance and possibiliy a some charactristsics of each team over the past 27 seasons.  \n",
    "The final output of analysis should be easy to understand by wide range of audeince, therefore it must be visualized in a form of graph or table and should not require some special knowledge of mathmatics. HOwever, it will require some basic knowledge on football.    \n",
    "\n",
    "The source data for this project is all match results from 1993/1994 season to present. Format of source data is csv and single csv file contains a match result of one season. \n",
    "\n",
    "any weaknesses or potential caveats in your approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premier League match result data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was originally looking for a one data that contains all the result from 1993/1994 season to 2019/2020 season. However, I could only find indivisual CSV files for each seasons. At the begginning, I was going to download eachcsv files manually, but it is much effcient to scrape them from the web page. I scrrape all data set from the following web page http://www.football-data.co.uk/englandm.php using BeautifulSoup. Initially, each csv files are scraped individually, then they will be combine to two different csv files.\n",
    "\n",
    "I notice that data after 2000/2001 season has more stats compare to seasons before 2000/2001 season. Data before 2000/2001 season contains only a match results where seasons after 2000/2001 contains more details stats of each match such as number of corner kicks, free kicks, and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re \n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webpage that I scrape CSV files from.\n",
    "url = \"http://www.football-data.co.uk/englandm.php\"\n",
    "all_files = [] #this list contains names of each csv files\n",
    "# download all csv files from the web page \n",
    "with requests.Session() as req:\n",
    "    r = req.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    for link in soup.find_all(href=re.compile('E0.csv')):\n",
    "        file = link.get('href')\n",
    "        new_link = \"http://www.football-data.co.uk/\" + file\n",
    "        r = req.get(new_link)\n",
    "        name = file.rsplit(\"/\", 2)[-2]\n",
    "        name = name + \".csv\"\n",
    "        all_files.append(name)\n",
    "        with open(name, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "all_files.reverse() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_files is a list that contains name of each csv files, and this list start with 2020/2021 season. But it makes more sence to have them in past to present order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/94 season to 99/00 season\n",
      "['9394.csv', '9495.csv', '9596.csv', '9697.csv', '9798.csv', '9899.csv', '9900.csv']\n",
      "00/01 season to present\n",
      "['0001.csv', '0102.csv', '0203.csv', '0304.csv', '0405.csv', '0506.csv', '0607.csv', '0708.csv', '0809.csv', '0910.csv', '1011.csv', '1112.csv', '1213.csv', '1314.csv', '1415.csv', '1516.csv', '1617.csv', '1718.csv', '1819.csv', '1920.csv', '2021.csv']\n"
     ]
    }
   ],
   "source": [
    "# group all csv files into two different group \n",
    "file_group1 = []\n",
    "file_group2 = []\n",
    "for i in range(len(all_files)):\n",
    "    if i < 7:\n",
    "        file_group1.append(all_files[i])\n",
    "    else:\n",
    "        file_group2.append(all_files[i])\n",
    "\n",
    "print(\"93/94 season to 99/00 season\") \n",
    "print(file_group1)\n",
    "print(\"00/01 season to present\") \n",
    "print(file_group2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I grouped files based on similarity of data that are contain in each files.  As I mnetioned, first group contains less data about each match than second group of files. By separating them into two, I can do more analysis on second group since there are only limited possibility of analysis on first group.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will manipulate data by modify and combine csv files in order to carry out analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify some files that contains unncessary blank rows \n",
    "def modify_file(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df['Div'].replace(' ', np.nan, inplace=True)\n",
    "    df.dropna(subset=['Div'], inplace=True)\n",
    "    df.to_csv(file, index=False)\n",
    "    \n",
    "for file in file_group1:\n",
    "    modify_file(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that files in group 1 contains unncessary blank rows at the end of each file, and function modify_file( ) remove those blank rows. Merging those files without modifying them will cause huge gaps within the merged file and it could cause some errorswhile data annalysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge group 1 into one file called \"9300.csv\" \n",
    "df_group1 = (pd.read_csv(f) for f in file_group1)\n",
    "df_group1_merged = pd.concat(df_group1, sort=False)\n",
    "df_group1_merged.to_csv(\"9300.csv\")\n",
    "\n",
    "# merge group 2 into one file called \"0021.csv\"\n",
    "df = pd.read_csv(\"1920.csv\")\n",
    "header = list(df.columns.values)\n",
    "df_group2 = (pd.read_csv(f, names=headers, encoding='latin1') for f in file_group2)\n",
    "df_group2_merged = pd.concat(df_group2, names = headers)\n",
    "df_group2_merged.to_csv(\"0021.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it is ideal to define one function and use it to combine csv files to avoide repittion of code. However, second group of files contains more columns and thererfore it require a bit different approcah. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary files from project \n",
    "total_file_num = len(all_files)\n",
    "for i in range(0, total_file_num):\n",
    "    os.remove(all_files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I have two files that both contain data about EPL matches with second file contains more stats. I will carry two types of analysis: one for both file and another one for just second file (0021.csv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
